{
  "best_global_step": 4400,
  "best_metric": 0.47292301058769226,
  "best_model_checkpoint": "/content/drive/MyDrive/AI_Models/qwen_coder_checkpoints/checkpoint-4400",
  "epoch": 1.4781634938409853,
  "eval_steps": 200,
  "global_step": 6600,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.005599104143337066,
      "grad_norm": 0.5534399151802063,
      "learning_rate": 4.8e-05,
      "loss": 0.7727,
      "step": 25
    },
    {
      "epoch": 0.011198208286674132,
      "grad_norm": 0.221335306763649,
      "learning_rate": 9.8e-05,
      "loss": 0.5569,
      "step": 50
    },
    {
      "epoch": 0.0167973124300112,
      "grad_norm": 0.22664403915405273,
      "learning_rate": 0.000148,
      "loss": 0.5291,
      "step": 75
    },
    {
      "epoch": 0.022396416573348264,
      "grad_norm": 0.25526607036590576,
      "learning_rate": 0.00019800000000000002,
      "loss": 0.5129,
      "step": 100
    },
    {
      "epoch": 0.027995520716685332,
      "grad_norm": 0.2495206594467163,
      "learning_rate": 0.0001999963544069536,
      "loss": 0.5196,
      "step": 125
    },
    {
      "epoch": 0.0335946248600224,
      "grad_norm": 0.22800952196121216,
      "learning_rate": 0.00019998480399236517,
      "loss": 0.5236,
      "step": 150
    },
    {
      "epoch": 0.03919372900335946,
      "grad_norm": 0.2122439742088318,
      "learning_rate": 0.00019996534334084585,
      "loss": 0.5016,
      "step": 175
    },
    {
      "epoch": 0.04479283314669653,
      "grad_norm": 0.21862265467643738,
      "learning_rate": 0.00019993797399201318,
      "loss": 0.4947,
      "step": 200
    },
    {
      "epoch": 0.04479283314669653,
      "eval_loss": 0.5082105398178101,
      "eval_runtime": 119.167,
      "eval_samples_per_second": 31.552,
      "eval_steps_per_second": 3.944,
      "step": 200
    },
    {
      "epoch": 0.05039193729003359,
      "grad_norm": 0.22589635848999023,
      "learning_rate": 0.0001999026981111766,
      "loss": 0.5118,
      "step": 225
    },
    {
      "epoch": 0.055991041433370664,
      "grad_norm": 0.20493489503860474,
      "learning_rate": 0.0001998595184891659,
      "loss": 0.4949,
      "step": 250
    },
    {
      "epoch": 0.06159014557670773,
      "grad_norm": 0.2156175822019577,
      "learning_rate": 0.00019980843854211063,
      "loss": 0.492,
      "step": 275
    },
    {
      "epoch": 0.0671892497200448,
      "grad_norm": 0.20777370035648346,
      "learning_rate": 0.00019974946231116972,
      "loss": 0.4823,
      "step": 300
    },
    {
      "epoch": 0.07278835386338185,
      "grad_norm": 0.20404931902885437,
      "learning_rate": 0.00019968259446221176,
      "loss": 0.5011,
      "step": 325
    },
    {
      "epoch": 0.07838745800671892,
      "grad_norm": 0.21671642363071442,
      "learning_rate": 0.000199607840285446,
      "loss": 0.5067,
      "step": 350
    },
    {
      "epoch": 0.083986562150056,
      "grad_norm": 0.23128566145896912,
      "learning_rate": 0.0001995252056950036,
      "loss": 0.5179,
      "step": 375
    },
    {
      "epoch": 0.08958566629339305,
      "grad_norm": 0.20076140761375427,
      "learning_rate": 0.00019943469722846993,
      "loss": 0.5078,
      "step": 400
    },
    {
      "epoch": 0.08958566629339305,
      "eval_loss": 0.5022410154342651,
      "eval_runtime": 118.7376,
      "eval_samples_per_second": 31.666,
      "eval_steps_per_second": 3.958,
      "step": 400
    },
    {
      "epoch": 0.09518477043673013,
      "grad_norm": 0.2057257443666458,
      "learning_rate": 0.00019933632204636724,
      "loss": 0.5121,
      "step": 425
    },
    {
      "epoch": 0.10078387458006718,
      "grad_norm": 0.21425919234752655,
      "learning_rate": 0.00019923008793158817,
      "loss": 0.4918,
      "step": 450
    },
    {
      "epoch": 0.10638297872340426,
      "grad_norm": 0.24278397858142853,
      "learning_rate": 0.00019911600328878013,
      "loss": 0.5075,
      "step": 475
    },
    {
      "epoch": 0.11198208286674133,
      "grad_norm": 0.22667017579078674,
      "learning_rate": 0.0001989940771436802,
      "loss": 0.5075,
      "step": 500
    },
    {
      "epoch": 0.11758118701007839,
      "grad_norm": 0.23432020843029022,
      "learning_rate": 0.00019886431914240116,
      "loss": 0.4967,
      "step": 525
    },
    {
      "epoch": 0.12318029115341546,
      "grad_norm": 0.21776311099529266,
      "learning_rate": 0.00019872673955066833,
      "loss": 0.4997,
      "step": 550
    },
    {
      "epoch": 0.12877939529675253,
      "grad_norm": 0.23650090396404266,
      "learning_rate": 0.00019858134925300735,
      "loss": 0.4874,
      "step": 575
    },
    {
      "epoch": 0.1343784994400896,
      "grad_norm": 0.2100389003753662,
      "learning_rate": 0.0001984281597518832,
      "loss": 0.4979,
      "step": 600
    },
    {
      "epoch": 0.1343784994400896,
      "eval_loss": 0.49740833044052124,
      "eval_runtime": 118.7178,
      "eval_samples_per_second": 31.672,
      "eval_steps_per_second": 3.959,
      "step": 600
    },
    {
      "epoch": 0.13997760358342665,
      "grad_norm": 0.22277964651584625,
      "learning_rate": 0.00019826718316679008,
      "loss": 0.5059,
      "step": 625
    },
    {
      "epoch": 0.1455767077267637,
      "grad_norm": 0.22662585973739624,
      "learning_rate": 0.00019809843223329252,
      "loss": 0.4939,
      "step": 650
    },
    {
      "epoch": 0.1511758118701008,
      "grad_norm": 0.2280283272266388,
      "learning_rate": 0.000197921920302018,
      "loss": 0.5116,
      "step": 675
    },
    {
      "epoch": 0.15677491601343785,
      "grad_norm": 0.21305368840694427,
      "learning_rate": 0.00019773766133760048,
      "loss": 0.4975,
      "step": 700
    },
    {
      "epoch": 0.1623740201567749,
      "grad_norm": 0.24560235440731049,
      "learning_rate": 0.00019754566991757587,
      "loss": 0.5116,
      "step": 725
    },
    {
      "epoch": 0.167973124300112,
      "grad_norm": 0.21879960596561432,
      "learning_rate": 0.00019734596123122854,
      "loss": 0.4983,
      "step": 750
    },
    {
      "epoch": 0.17357222844344905,
      "grad_norm": 0.20472745597362518,
      "learning_rate": 0.00019713855107838973,
      "loss": 0.4936,
      "step": 775
    },
    {
      "epoch": 0.1791713325867861,
      "grad_norm": 0.23918287456035614,
      "learning_rate": 0.0001969234558681874,
      "loss": 0.4996,
      "step": 800
    },
    {
      "epoch": 0.1791713325867861,
      "eval_loss": 0.49600762128829956,
      "eval_runtime": 118.6003,
      "eval_samples_per_second": 31.703,
      "eval_steps_per_second": 3.963,
      "step": 800
    },
    {
      "epoch": 0.18477043673012317,
      "grad_norm": 0.22625868022441864,
      "learning_rate": 0.0001967006926177483,
      "loss": 0.4849,
      "step": 825
    },
    {
      "epoch": 0.19036954087346025,
      "grad_norm": 0.24073606729507446,
      "learning_rate": 0.00019647027895085143,
      "loss": 0.4969,
      "step": 850
    },
    {
      "epoch": 0.1959686450167973,
      "grad_norm": 0.2247675508260727,
      "learning_rate": 0.0001962322330965338,
      "loss": 0.4995,
      "step": 875
    },
    {
      "epoch": 0.20156774916013437,
      "grad_norm": 0.22561123967170715,
      "learning_rate": 0.00019598657388764838,
      "loss": 0.5035,
      "step": 900
    },
    {
      "epoch": 0.20716685330347145,
      "grad_norm": 0.2311924397945404,
      "learning_rate": 0.000195733320759374,
      "loss": 0.5029,
      "step": 925
    },
    {
      "epoch": 0.2127659574468085,
      "grad_norm": 0.21790507435798645,
      "learning_rate": 0.00019547249374767778,
      "loss": 0.5055,
      "step": 950
    },
    {
      "epoch": 0.21836506159014557,
      "grad_norm": 0.20796862244606018,
      "learning_rate": 0.0001952041134877301,
      "loss": 0.4838,
      "step": 975
    },
    {
      "epoch": 0.22396416573348266,
      "grad_norm": 0.22913049161434174,
      "learning_rate": 0.0001949282012122719,
      "loss": 0.5089,
      "step": 1000
    },
    {
      "epoch": 0.22396416573348266,
      "eval_loss": 0.49435925483703613,
      "eval_runtime": 118.3867,
      "eval_samples_per_second": 31.76,
      "eval_steps_per_second": 3.97,
      "step": 1000
    },
    {
      "epoch": 0.22956326987681971,
      "grad_norm": 0.22538991272449493,
      "learning_rate": 0.00019464477874993496,
      "loss": 0.4843,
      "step": 1025
    },
    {
      "epoch": 0.23516237402015677,
      "grad_norm": 0.23409916460514069,
      "learning_rate": 0.00019435386852351494,
      "loss": 0.495,
      "step": 1050
    },
    {
      "epoch": 0.24076147816349383,
      "grad_norm": 0.23157168924808502,
      "learning_rate": 0.0001940554935481974,
      "loss": 0.5022,
      "step": 1075
    },
    {
      "epoch": 0.24636058230683092,
      "grad_norm": 0.23481373488903046,
      "learning_rate": 0.00019374967742973699,
      "loss": 0.4858,
      "step": 1100
    },
    {
      "epoch": 0.251959686450168,
      "grad_norm": 0.21280130743980408,
      "learning_rate": 0.00019343644436258978,
      "loss": 0.4938,
      "step": 1125
    },
    {
      "epoch": 0.25755879059350506,
      "grad_norm": 0.21653658151626587,
      "learning_rate": 0.0001931158191279993,
      "loss": 0.504,
      "step": 1150
    },
    {
      "epoch": 0.2631578947368421,
      "grad_norm": 0.23299738764762878,
      "learning_rate": 0.00019278782709203598,
      "loss": 0.4996,
      "step": 1175
    },
    {
      "epoch": 0.2687569988801792,
      "grad_norm": 0.23336146771907806,
      "learning_rate": 0.0001924524942035901,
      "loss": 0.49,
      "step": 1200
    },
    {
      "epoch": 0.2687569988801792,
      "eval_loss": 0.4931259751319885,
      "eval_runtime": 118.4857,
      "eval_samples_per_second": 31.734,
      "eval_steps_per_second": 3.967,
      "step": 1200
    },
    {
      "epoch": 0.27435610302351626,
      "grad_norm": 0.2380799502134323,
      "learning_rate": 0.00019210984699231912,
      "loss": 0.4895,
      "step": 1225
    },
    {
      "epoch": 0.2799552071668533,
      "grad_norm": 0.2575049102306366,
      "learning_rate": 0.00019175991256654862,
      "loss": 0.4995,
      "step": 1250
    },
    {
      "epoch": 0.2855543113101904,
      "grad_norm": 0.20026740431785583,
      "learning_rate": 0.00019140271861112785,
      "loss": 0.4925,
      "step": 1275
    },
    {
      "epoch": 0.2911534154535274,
      "grad_norm": 0.2330513894557953,
      "learning_rate": 0.0001910382933852392,
      "loss": 0.4897,
      "step": 1300
    },
    {
      "epoch": 0.2967525195968645,
      "grad_norm": 0.2146257609128952,
      "learning_rate": 0.0001906666657201627,
      "loss": 0.4947,
      "step": 1325
    },
    {
      "epoch": 0.3023516237402016,
      "grad_norm": 0.21983854472637177,
      "learning_rate": 0.00019028786501699494,
      "loss": 0.4972,
      "step": 1350
    },
    {
      "epoch": 0.3079507278835386,
      "grad_norm": 0.25491780042648315,
      "learning_rate": 0.00018990192124432307,
      "loss": 0.4962,
      "step": 1375
    },
    {
      "epoch": 0.3135498320268757,
      "grad_norm": 0.22496388852596283,
      "learning_rate": 0.00018950886493585386,
      "loss": 0.4957,
      "step": 1400
    },
    {
      "epoch": 0.3135498320268757,
      "eval_loss": 0.49211427569389343,
      "eval_runtime": 118.5733,
      "eval_samples_per_second": 31.71,
      "eval_steps_per_second": 3.964,
      "step": 1400
    },
    {
      "epoch": 0.3191489361702128,
      "grad_norm": 0.25964102149009705,
      "learning_rate": 0.00018910872718799792,
      "loss": 0.5047,
      "step": 1425
    },
    {
      "epoch": 0.3247480403135498,
      "grad_norm": 0.2854689955711365,
      "learning_rate": 0.0001887015396574098,
      "loss": 0.4882,
      "step": 1450
    },
    {
      "epoch": 0.3303471444568869,
      "grad_norm": 0.26032811403274536,
      "learning_rate": 0.00018828733455848317,
      "loss": 0.4935,
      "step": 1475
    },
    {
      "epoch": 0.335946248600224,
      "grad_norm": 0.21019184589385986,
      "learning_rate": 0.00018786614466080237,
      "loss": 0.4843,
      "step": 1500
    },
    {
      "epoch": 0.341545352743561,
      "grad_norm": 0.25703075528144836,
      "learning_rate": 0.00018743800328654994,
      "loss": 0.4937,
      "step": 1525
    },
    {
      "epoch": 0.3471444568868981,
      "grad_norm": 0.22521094977855682,
      "learning_rate": 0.00018700294430787015,
      "loss": 0.4808,
      "step": 1550
    },
    {
      "epoch": 0.3527435610302352,
      "grad_norm": 0.24378079175949097,
      "learning_rate": 0.00018656100214418944,
      "loss": 0.4889,
      "step": 1575
    },
    {
      "epoch": 0.3583426651735722,
      "grad_norm": 0.2529197037220001,
      "learning_rate": 0.00018611221175949316,
      "loss": 0.4888,
      "step": 1600
    },
    {
      "epoch": 0.3583426651735722,
      "eval_loss": 0.48990398645401,
      "eval_runtime": 118.2148,
      "eval_samples_per_second": 31.807,
      "eval_steps_per_second": 3.976,
      "step": 1600
    },
    {
      "epoch": 0.3639417693169093,
      "grad_norm": 0.22857801616191864,
      "learning_rate": 0.00018565660865955947,
      "loss": 0.4918,
      "step": 1625
    },
    {
      "epoch": 0.36954087346024633,
      "grad_norm": 0.24125604331493378,
      "learning_rate": 0.0001851942288891505,
      "loss": 0.5036,
      "step": 1650
    },
    {
      "epoch": 0.3751399776035834,
      "grad_norm": 0.23315779864788055,
      "learning_rate": 0.00018472510902916035,
      "loss": 0.4842,
      "step": 1675
    },
    {
      "epoch": 0.3807390817469205,
      "grad_norm": 0.235369473695755,
      "learning_rate": 0.00018424928619372135,
      "loss": 0.5258,
      "step": 1700
    },
    {
      "epoch": 0.38633818589025753,
      "grad_norm": 0.22377143800258636,
      "learning_rate": 0.00018376679802726762,
      "loss": 0.4964,
      "step": 1725
    },
    {
      "epoch": 0.3919372900335946,
      "grad_norm": 0.2560816705226898,
      "learning_rate": 0.00018327768270155683,
      "loss": 0.4876,
      "step": 1750
    },
    {
      "epoch": 0.3975363941769317,
      "grad_norm": 0.21535997092723846,
      "learning_rate": 0.0001827819789126504,
      "loss": 0.4903,
      "step": 1775
    },
    {
      "epoch": 0.40313549832026874,
      "grad_norm": 0.28225868940353394,
      "learning_rate": 0.00018227972587785195,
      "loss": 0.4923,
      "step": 1800
    },
    {
      "epoch": 0.40313549832026874,
      "eval_loss": 0.48919031023979187,
      "eval_runtime": 118.3733,
      "eval_samples_per_second": 31.764,
      "eval_steps_per_second": 3.97,
      "step": 1800
    },
    {
      "epoch": 0.4087346024636058,
      "grad_norm": 0.2781079113483429,
      "learning_rate": 0.00018177096333260476,
      "loss": 0.4802,
      "step": 1825
    },
    {
      "epoch": 0.4143337066069429,
      "grad_norm": 0.2584962248802185,
      "learning_rate": 0.000181255731527348,
      "loss": 0.4888,
      "step": 1850
    },
    {
      "epoch": 0.41993281075027994,
      "grad_norm": 0.24379637837409973,
      "learning_rate": 0.00018073407122433247,
      "loss": 0.4792,
      "step": 1875
    },
    {
      "epoch": 0.425531914893617,
      "grad_norm": 0.23875612020492554,
      "learning_rate": 0.0001802060236943956,
      "loss": 0.49,
      "step": 1900
    },
    {
      "epoch": 0.4311310190369541,
      "grad_norm": 0.2371537685394287,
      "learning_rate": 0.00017967163071369645,
      "loss": 0.4988,
      "step": 1925
    },
    {
      "epoch": 0.43673012318029114,
      "grad_norm": 0.24989289045333862,
      "learning_rate": 0.00017913093456041053,
      "loss": 0.5044,
      "step": 1950
    },
    {
      "epoch": 0.4423292273236282,
      "grad_norm": 0.22658206522464752,
      "learning_rate": 0.00017858397801138502,
      "loss": 0.4808,
      "step": 1975
    },
    {
      "epoch": 0.4479283314669653,
      "grad_norm": 0.23954537510871887,
      "learning_rate": 0.00017803080433875446,
      "loss": 0.4872,
      "step": 2000
    },
    {
      "epoch": 0.4479283314669653,
      "eval_loss": 0.4874652624130249,
      "eval_runtime": 118.3846,
      "eval_samples_per_second": 31.761,
      "eval_steps_per_second": 3.97,
      "step": 2000
    },
    {
      "epoch": 0.45352743561030234,
      "grad_norm": 0.2424570620059967,
      "learning_rate": 0.0001774714573065174,
      "loss": 0.5006,
      "step": 2025
    },
    {
      "epoch": 0.45912653975363943,
      "grad_norm": 0.26078134775161743,
      "learning_rate": 0.00017690598116707395,
      "loss": 0.4867,
      "step": 2050
    },
    {
      "epoch": 0.46472564389697646,
      "grad_norm": 0.24674449861049652,
      "learning_rate": 0.00017633442065772482,
      "loss": 0.5033,
      "step": 2075
    },
    {
      "epoch": 0.47032474804031354,
      "grad_norm": 0.2705247104167938,
      "learning_rate": 0.00017575682099713196,
      "loss": 0.4891,
      "step": 2100
    },
    {
      "epoch": 0.47592385218365063,
      "grad_norm": 0.21505430340766907,
      "learning_rate": 0.000175173227881741,
      "loss": 0.4977,
      "step": 2125
    },
    {
      "epoch": 0.48152295632698766,
      "grad_norm": 0.3529491126537323,
      "learning_rate": 0.0001745836874821662,
      "loss": 0.4981,
      "step": 2150
    },
    {
      "epoch": 0.48712206047032475,
      "grad_norm": 0.2643324136734009,
      "learning_rate": 0.0001739882464395376,
      "loss": 0.4844,
      "step": 2175
    },
    {
      "epoch": 0.49272116461366183,
      "grad_norm": 0.24431189894676208,
      "learning_rate": 0.00017338695186181093,
      "loss": 0.4892,
      "step": 2200
    },
    {
      "epoch": 0.49272116461366183,
      "eval_loss": 0.48690152168273926,
      "eval_runtime": 118.2958,
      "eval_samples_per_second": 31.785,
      "eval_steps_per_second": 3.973,
      "step": 2200
    },
    {
      "epoch": 0.49832026875699886,
      "grad_norm": 0.23386768996715546,
      "learning_rate": 0.00017277985132004088,
      "loss": 0.4807,
      "step": 2225
    },
    {
      "epoch": 0.503919372900336,
      "grad_norm": 0.2494257241487503,
      "learning_rate": 0.00017216699284461736,
      "loss": 0.4973,
      "step": 2250
    },
    {
      "epoch": 0.509518477043673,
      "grad_norm": 0.2218037098646164,
      "learning_rate": 0.00017154842492146584,
      "loss": 0.4826,
      "step": 2275
    },
    {
      "epoch": 0.5151175811870101,
      "grad_norm": 0.252857506275177,
      "learning_rate": 0.00017092419648821112,
      "loss": 0.4797,
      "step": 2300
    },
    {
      "epoch": 0.5207166853303471,
      "grad_norm": 0.22616109251976013,
      "learning_rate": 0.00017029435693030587,
      "loss": 0.4893,
      "step": 2325
    },
    {
      "epoch": 0.5263157894736842,
      "grad_norm": 0.2535543143749237,
      "learning_rate": 0.00016965895607712355,
      "loss": 0.477,
      "step": 2350
    },
    {
      "epoch": 0.5319148936170213,
      "grad_norm": 0.23343458771705627,
      "learning_rate": 0.000169018044198016,
      "loss": 0.4807,
      "step": 2375
    },
    {
      "epoch": 0.5375139977603584,
      "grad_norm": 0.2719551622867584,
      "learning_rate": 0.0001683716719983365,
      "loss": 0.4972,
      "step": 2400
    },
    {
      "epoch": 0.5375139977603584,
      "eval_loss": 0.4857083857059479,
      "eval_runtime": 118.6255,
      "eval_samples_per_second": 31.696,
      "eval_steps_per_second": 3.962,
      "step": 2400
    },
    {
      "epoch": 0.5431131019036954,
      "grad_norm": 0.24544481933116913,
      "learning_rate": 0.00016771989061542845,
      "loss": 0.4758,
      "step": 2425
    },
    {
      "epoch": 0.5487122060470325,
      "grad_norm": 0.230918288230896,
      "learning_rate": 0.00016706275161457933,
      "loss": 0.4835,
      "step": 2450
    },
    {
      "epoch": 0.5543113101903695,
      "grad_norm": 0.2582111358642578,
      "learning_rate": 0.00016640030698494133,
      "loss": 0.4714,
      "step": 2475
    },
    {
      "epoch": 0.5599104143337066,
      "grad_norm": 0.23581206798553467,
      "learning_rate": 0.00016573260913541824,
      "loss": 0.4838,
      "step": 2500
    },
    {
      "epoch": 0.5655095184770437,
      "grad_norm": 0.23117142915725708,
      "learning_rate": 0.0001650597108905192,
      "loss": 0.4948,
      "step": 2525
    },
    {
      "epoch": 0.5711086226203808,
      "grad_norm": 0.26626986265182495,
      "learning_rate": 0.00016438166548617936,
      "loss": 0.4904,
      "step": 2550
    },
    {
      "epoch": 0.5767077267637178,
      "grad_norm": 0.2552661597728729,
      "learning_rate": 0.00016369852656554837,
      "loss": 0.4847,
      "step": 2575
    },
    {
      "epoch": 0.5823068309070548,
      "grad_norm": 0.2687646150588989,
      "learning_rate": 0.0001630103481747463,
      "loss": 0.4885,
      "step": 2600
    },
    {
      "epoch": 0.5823068309070548,
      "eval_loss": 0.4842981994152069,
      "eval_runtime": 118.6128,
      "eval_samples_per_second": 31.7,
      "eval_steps_per_second": 3.962,
      "step": 2600
    },
    {
      "epoch": 0.5879059350503919,
      "grad_norm": 0.23315393924713135,
      "learning_rate": 0.00016231718475858775,
      "loss": 0.4838,
      "step": 2625
    },
    {
      "epoch": 0.593505039193729,
      "grad_norm": 0.2480563521385193,
      "learning_rate": 0.00016161909115627464,
      "loss": 0.4979,
      "step": 2650
    },
    {
      "epoch": 0.5991041433370661,
      "grad_norm": 0.25125783681869507,
      "learning_rate": 0.0001609161225970576,
      "loss": 0.4941,
      "step": 2675
    },
    {
      "epoch": 0.6047032474804032,
      "grad_norm": 0.2290894091129303,
      "learning_rate": 0.00016020833469586638,
      "loss": 0.4849,
      "step": 2700
    },
    {
      "epoch": 0.6103023516237402,
      "grad_norm": 0.24857792258262634,
      "learning_rate": 0.0001594957834489102,
      "loss": 0.4814,
      "step": 2725
    },
    {
      "epoch": 0.6159014557670772,
      "grad_norm": 0.24334870278835297,
      "learning_rate": 0.00015877852522924732,
      "loss": 0.4841,
      "step": 2750
    },
    {
      "epoch": 0.6215005599104143,
      "grad_norm": 0.2553757429122925,
      "learning_rate": 0.00015805661678232544,
      "loss": 0.4929,
      "step": 2775
    },
    {
      "epoch": 0.6270996640537514,
      "grad_norm": 0.23728680610656738,
      "learning_rate": 0.00015733011522149206,
      "loss": 0.4881,
      "step": 2800
    },
    {
      "epoch": 0.6270996640537514,
      "eval_loss": 0.4829098582267761,
      "eval_runtime": 118.4703,
      "eval_samples_per_second": 31.738,
      "eval_steps_per_second": 3.967,
      "step": 2800
    },
    {
      "epoch": 0.6326987681970885,
      "grad_norm": 0.247182697057724,
      "learning_rate": 0.0001565990780234761,
      "loss": 0.4785,
      "step": 2825
    },
    {
      "epoch": 0.6382978723404256,
      "grad_norm": 0.24445436894893646,
      "learning_rate": 0.00015586356302384067,
      "loss": 0.4654,
      "step": 2850
    },
    {
      "epoch": 0.6438969764837627,
      "grad_norm": 0.2547202706336975,
      "learning_rate": 0.0001551236284124075,
      "loss": 0.4941,
      "step": 2875
    },
    {
      "epoch": 0.6494960806270996,
      "grad_norm": 0.2417401224374771,
      "learning_rate": 0.00015437933272865304,
      "loss": 0.4859,
      "step": 2900
    },
    {
      "epoch": 0.6550951847704367,
      "grad_norm": 0.23716610670089722,
      "learning_rate": 0.00015363073485707754,
      "loss": 0.4696,
      "step": 2925
    },
    {
      "epoch": 0.6606942889137738,
      "grad_norm": 0.25381964445114136,
      "learning_rate": 0.00015287789402254604,
      "loss": 0.464,
      "step": 2950
    },
    {
      "epoch": 0.6662933930571109,
      "grad_norm": 0.2386624962091446,
      "learning_rate": 0.00015212086978560316,
      "loss": 0.4883,
      "step": 2975
    },
    {
      "epoch": 0.671892497200448,
      "grad_norm": 0.2402988225221634,
      "learning_rate": 0.00015135972203776072,
      "loss": 0.4798,
      "step": 3000
    },
    {
      "epoch": 0.671892497200448,
      "eval_loss": 0.48174554109573364,
      "eval_runtime": 118.5829,
      "eval_samples_per_second": 31.708,
      "eval_steps_per_second": 3.963,
      "step": 3000
    },
    {
      "epoch": 0.6774916013437849,
      "grad_norm": 0.24141252040863037,
      "learning_rate": 0.0001505945109967597,
      "loss": 0.4928,
      "step": 3025
    },
    {
      "epoch": 0.683090705487122,
      "grad_norm": 0.25576111674308777,
      "learning_rate": 0.00014982529720180597,
      "loss": 0.4875,
      "step": 3050
    },
    {
      "epoch": 0.6886898096304591,
      "grad_norm": 0.2612456977367401,
      "learning_rate": 0.00014905214150878093,
      "loss": 0.4712,
      "step": 3075
    },
    {
      "epoch": 0.6942889137737962,
      "grad_norm": 0.26011812686920166,
      "learning_rate": 0.00014827510508542676,
      "loss": 0.4856,
      "step": 3100
    },
    {
      "epoch": 0.6998880179171333,
      "grad_norm": 0.2467600703239441,
      "learning_rate": 0.00014749424940650732,
      "loss": 0.4908,
      "step": 3125
    },
    {
      "epoch": 0.7054871220604704,
      "grad_norm": 0.22777174413204193,
      "learning_rate": 0.0001467096362489445,
      "loss": 0.4815,
      "step": 3150
    },
    {
      "epoch": 0.7110862262038073,
      "grad_norm": 0.26955071091651917,
      "learning_rate": 0.0001459213276869309,
      "loss": 0.4973,
      "step": 3175
    },
    {
      "epoch": 0.7166853303471444,
      "grad_norm": 0.2378178834915161,
      "learning_rate": 0.0001451293860870187,
      "loss": 0.4671,
      "step": 3200
    },
    {
      "epoch": 0.7166853303471444,
      "eval_loss": 0.4801584780216217,
      "eval_runtime": 118.545,
      "eval_samples_per_second": 31.718,
      "eval_steps_per_second": 3.965,
      "step": 3200
    },
    {
      "epoch": 0.7222844344904815,
      "grad_norm": 0.26208239793777466,
      "learning_rate": 0.00014433387410318576,
      "loss": 0.4633,
      "step": 3225
    },
    {
      "epoch": 0.7278835386338186,
      "grad_norm": 0.23346403241157532,
      "learning_rate": 0.00014353485467187858,
      "loss": 0.4858,
      "step": 3250
    },
    {
      "epoch": 0.7334826427771557,
      "grad_norm": 0.26980680227279663,
      "learning_rate": 0.00014273239100703333,
      "loss": 0.4767,
      "step": 3275
    },
    {
      "epoch": 0.7390817469204927,
      "grad_norm": 0.24592873454093933,
      "learning_rate": 0.00014192654659507458,
      "loss": 0.4925,
      "step": 3300
    },
    {
      "epoch": 0.7446808510638298,
      "grad_norm": 0.22636356949806213,
      "learning_rate": 0.0001411173851898927,
      "loss": 0.4676,
      "step": 3325
    },
    {
      "epoch": 0.7502799552071668,
      "grad_norm": 0.27557647228240967,
      "learning_rate": 0.00014030497080779982,
      "loss": 0.47,
      "step": 3350
    },
    {
      "epoch": 0.7558790593505039,
      "grad_norm": 0.24012938141822815,
      "learning_rate": 0.00013948936772246553,
      "loss": 0.4944,
      "step": 3375
    },
    {
      "epoch": 0.761478163493841,
      "grad_norm": 0.2592785954475403,
      "learning_rate": 0.00013867064045983168,
      "loss": 0.484,
      "step": 3400
    },
    {
      "epoch": 0.761478163493841,
      "eval_loss": 0.4787876009941101,
      "eval_runtime": 118.4686,
      "eval_samples_per_second": 31.738,
      "eval_steps_per_second": 3.967,
      "step": 3400
    },
    {
      "epoch": 0.7670772676371781,
      "grad_norm": 0.2639683187007904,
      "learning_rate": 0.00013784885379300742,
      "loss": 0.4753,
      "step": 3425
    },
    {
      "epoch": 0.7726763717805151,
      "grad_norm": 0.27386870980262756,
      "learning_rate": 0.0001370240727371449,
      "loss": 0.4758,
      "step": 3450
    },
    {
      "epoch": 0.7782754759238522,
      "grad_norm": 0.26441285014152527,
      "learning_rate": 0.00013619636254429552,
      "loss": 0.5007,
      "step": 3475
    },
    {
      "epoch": 0.7838745800671892,
      "grad_norm": 0.25714123249053955,
      "learning_rate": 0.00013536578869824756,
      "loss": 0.4678,
      "step": 3500
    },
    {
      "epoch": 0.7894736842105263,
      "grad_norm": 0.26200050115585327,
      "learning_rate": 0.00013453241690934546,
      "loss": 0.4834,
      "step": 3525
    },
    {
      "epoch": 0.7950727883538634,
      "grad_norm": 0.24196909368038177,
      "learning_rate": 0.00013369631310929122,
      "loss": 0.4759,
      "step": 3550
    },
    {
      "epoch": 0.8006718924972005,
      "grad_norm": 0.27427756786346436,
      "learning_rate": 0.0001328575434459283,
      "loss": 0.4777,
      "step": 3575
    },
    {
      "epoch": 0.8062709966405375,
      "grad_norm": 0.2866656184196472,
      "learning_rate": 0.00013201617427800817,
      "loss": 0.4864,
      "step": 3600
    },
    {
      "epoch": 0.8062709966405375,
      "eval_loss": 0.47787606716156006,
      "eval_runtime": 118.6509,
      "eval_samples_per_second": 31.69,
      "eval_steps_per_second": 3.961,
      "step": 3600
    },
    {
      "epoch": 0.8118701007838746,
      "grad_norm": 0.25823307037353516,
      "learning_rate": 0.00013117227216994068,
      "loss": 0.4743,
      "step": 3625
    },
    {
      "epoch": 0.8174692049272116,
      "grad_norm": 0.25226321816444397,
      "learning_rate": 0.00013032590388652757,
      "loss": 0.4878,
      "step": 3650
    },
    {
      "epoch": 0.8230683090705487,
      "grad_norm": 0.23222315311431885,
      "learning_rate": 0.00012947713638768066,
      "loss": 0.4794,
      "step": 3675
    },
    {
      "epoch": 0.8286674132138858,
      "grad_norm": 0.25696617364883423,
      "learning_rate": 0.00012862603682312412,
      "loss": 0.4753,
      "step": 3700
    },
    {
      "epoch": 0.8342665173572228,
      "grad_norm": 0.26568883657455444,
      "learning_rate": 0.00012777267252708216,
      "loss": 0.4677,
      "step": 3725
    },
    {
      "epoch": 0.8398656215005599,
      "grad_norm": 0.2497928887605667,
      "learning_rate": 0.00012691711101295186,
      "loss": 0.4715,
      "step": 3750
    },
    {
      "epoch": 0.845464725643897,
      "grad_norm": 0.25666722655296326,
      "learning_rate": 0.0001260594199679618,
      "loss": 0.4665,
      "step": 3775
    },
    {
      "epoch": 0.851063829787234,
      "grad_norm": 0.2654414176940918,
      "learning_rate": 0.00012519966724781713,
      "loss": 0.4725,
      "step": 3800
    },
    {
      "epoch": 0.851063829787234,
      "eval_loss": 0.47624272108078003,
      "eval_runtime": 118.6571,
      "eval_samples_per_second": 31.688,
      "eval_steps_per_second": 3.961,
      "step": 3800
    },
    {
      "epoch": 0.8566629339305711,
      "grad_norm": 0.24146394431591034,
      "learning_rate": 0.00012433792087133115,
      "loss": 0.4739,
      "step": 3825
    },
    {
      "epoch": 0.8622620380739082,
      "grad_norm": 0.2433691769838333,
      "learning_rate": 0.0001234742490150442,
      "loss": 0.485,
      "step": 3850
    },
    {
      "epoch": 0.8678611422172452,
      "grad_norm": 0.27485179901123047,
      "learning_rate": 0.00012260872000782955,
      "loss": 0.4804,
      "step": 3875
    },
    {
      "epoch": 0.8734602463605823,
      "grad_norm": 0.24021467566490173,
      "learning_rate": 0.00012174140232548801,
      "loss": 0.4841,
      "step": 3900
    },
    {
      "epoch": 0.8790593505039194,
      "grad_norm": 0.28030040860176086,
      "learning_rate": 0.00012087236458533033,
      "loss": 0.4794,
      "step": 3925
    },
    {
      "epoch": 0.8846584546472565,
      "grad_norm": 0.2500779330730438,
      "learning_rate": 0.00012000167554074851,
      "loss": 0.4869,
      "step": 3950
    },
    {
      "epoch": 0.8902575587905935,
      "grad_norm": 0.2860797345638275,
      "learning_rate": 0.00011912940407577653,
      "loss": 0.475,
      "step": 3975
    },
    {
      "epoch": 0.8958566629339306,
      "grad_norm": 0.2696155309677124,
      "learning_rate": 0.00011825561919964062,
      "loss": 0.4969,
      "step": 4000
    },
    {
      "epoch": 0.8958566629339306,
      "eval_loss": 0.475085973739624,
      "eval_runtime": 118.8046,
      "eval_samples_per_second": 31.649,
      "eval_steps_per_second": 3.956,
      "step": 4000
    },
    {
      "epoch": 0.9014557670772676,
      "grad_norm": 0.2552982270717621,
      "learning_rate": 0.00011738039004129954,
      "loss": 0.4778,
      "step": 4025
    },
    {
      "epoch": 0.9070548712206047,
      "grad_norm": 0.27439945936203003,
      "learning_rate": 0.0001165037858439757,
      "loss": 0.4827,
      "step": 4050
    },
    {
      "epoch": 0.9126539753639418,
      "grad_norm": 0.2466476410627365,
      "learning_rate": 0.0001156258759596767,
      "loss": 0.4888,
      "step": 4075
    },
    {
      "epoch": 0.9182530795072789,
      "grad_norm": 0.25979742407798767,
      "learning_rate": 0.00011474672984370891,
      "loss": 0.4683,
      "step": 4100
    },
    {
      "epoch": 0.9238521836506159,
      "grad_norm": 0.2483304738998413,
      "learning_rate": 0.00011386641704918235,
      "loss": 0.49,
      "step": 4125
    },
    {
      "epoch": 0.9294512877939529,
      "grad_norm": 0.26503250002861023,
      "learning_rate": 0.00011298500722150816,
      "loss": 0.4694,
      "step": 4150
    },
    {
      "epoch": 0.93505039193729,
      "grad_norm": 0.25445830821990967,
      "learning_rate": 0.00011210257009288847,
      "loss": 0.4818,
      "step": 4175
    },
    {
      "epoch": 0.9406494960806271,
      "grad_norm": 0.2741425633430481,
      "learning_rate": 0.00011121917547679987,
      "loss": 0.4716,
      "step": 4200
    },
    {
      "epoch": 0.9406494960806271,
      "eval_loss": 0.47377514839172363,
      "eval_runtime": 119.7049,
      "eval_samples_per_second": 31.411,
      "eval_steps_per_second": 3.926,
      "step": 4200
    },
    {
      "epoch": 0.9462486002239642,
      "grad_norm": 0.2350238561630249,
      "learning_rate": 0.00011033489326246984,
      "loss": 0.4534,
      "step": 4225
    },
    {
      "epoch": 0.9518477043673013,
      "grad_norm": 0.23366455733776093,
      "learning_rate": 0.00010944979340934773,
      "loss": 0.468,
      "step": 4250
    },
    {
      "epoch": 0.9574468085106383,
      "grad_norm": 0.23708538711071014,
      "learning_rate": 0.00010856394594156986,
      "loss": 0.4824,
      "step": 4275
    },
    {
      "epoch": 0.9630459126539753,
      "grad_norm": 0.2544681429862976,
      "learning_rate": 0.00010767742094241971,
      "loss": 0.4788,
      "step": 4300
    },
    {
      "epoch": 0.9686450167973124,
      "grad_norm": 0.25885191559791565,
      "learning_rate": 0.00010679028854878308,
      "loss": 0.4661,
      "step": 4325
    },
    {
      "epoch": 0.9742441209406495,
      "grad_norm": 0.24548517167568207,
      "learning_rate": 0.00010590261894559958,
      "loss": 0.4876,
      "step": 4350
    },
    {
      "epoch": 0.9798432250839866,
      "grad_norm": 0.2337372899055481,
      "learning_rate": 0.00010501448236030969,
      "loss": 0.488,
      "step": 4375
    },
    {
      "epoch": 0.9854423292273237,
      "grad_norm": 0.2583000659942627,
      "learning_rate": 0.000104125949057299,
      "loss": 0.4685,
      "step": 4400
    },
    {
      "epoch": 0.9854423292273237,
      "eval_loss": 0.47292301058769226,
      "eval_runtime": 119.5655,
      "eval_samples_per_second": 31.447,
      "eval_steps_per_second": 3.931,
      "step": 4400
    },
    {
      "epoch": 0.9910414333706606,
      "grad_norm": 0.2614099383354187,
      "learning_rate": 0.0001032370893323391,
      "loss": 0.4783,
      "step": 4425
    },
    {
      "epoch": 0.9966405375139977,
      "grad_norm": 0.2504318654537201,
      "learning_rate": 0.00010234797350702634,
      "loss": 0.4783,
      "step": 4450
    },
    {
      "epoch": 1.002239641657335,
      "grad_norm": 0.2531508803367615,
      "learning_rate": 0.00010145867192321819,
      "loss": 0.4533,
      "step": 4475
    },
    {
      "epoch": 1.007838745800672,
      "grad_norm": 0.2528424859046936,
      "learning_rate": 0.00010056925493746843,
      "loss": 0.411,
      "step": 4500
    },
    {
      "epoch": 1.0134378499440089,
      "grad_norm": 0.25787484645843506,
      "learning_rate": 9.967979291546059e-05,
      "loss": 0.4077,
      "step": 4525
    },
    {
      "epoch": 1.019036954087346,
      "grad_norm": 0.2949625849723816,
      "learning_rate": 9.879035622644147e-05,
      "loss": 0.4276,
      "step": 4550
    },
    {
      "epoch": 1.024636058230683,
      "grad_norm": 0.2915814220905304,
      "learning_rate": 9.790101523765345e-05,
      "loss": 0.3996,
      "step": 4575
    },
    {
      "epoch": 1.0302351623740202,
      "grad_norm": 0.2595655918121338,
      "learning_rate": 9.701184030876777e-05,
      "loss": 0.4098,
      "step": 4600
    },
    {
      "epoch": 1.0302351623740202,
      "eval_loss": 0.47834742069244385,
      "eval_runtime": 119.6964,
      "eval_samples_per_second": 31.413,
      "eval_steps_per_second": 3.927,
      "step": 4600
    },
    {
      "epoch": 1.0358342665173572,
      "grad_norm": 0.28332000970840454,
      "learning_rate": 9.612290178631786e-05,
      "loss": 0.4053,
      "step": 4625
    },
    {
      "epoch": 1.0414333706606942,
      "grad_norm": 0.2504887580871582,
      "learning_rate": 9.523426999813408e-05,
      "loss": 0.4128,
      "step": 4650
    },
    {
      "epoch": 1.0470324748040314,
      "grad_norm": 0.2838059663772583,
      "learning_rate": 9.434601524777962e-05,
      "loss": 0.4059,
      "step": 4675
    },
    {
      "epoch": 1.0526315789473684,
      "grad_norm": 0.2588092088699341,
      "learning_rate": 9.34582078089886e-05,
      "loss": 0.4068,
      "step": 4700
    },
    {
      "epoch": 1.0582306830907056,
      "grad_norm": 0.28932443261146545,
      "learning_rate": 9.257091792010634e-05,
      "loss": 0.4129,
      "step": 4725
    },
    {
      "epoch": 1.0638297872340425,
      "grad_norm": 0.2978253960609436,
      "learning_rate": 9.168421577853253e-05,
      "loss": 0.4156,
      "step": 4750
    },
    {
      "epoch": 1.0694288913773797,
      "grad_norm": 0.32150402665138245,
      "learning_rate": 9.079817153516755e-05,
      "loss": 0.4146,
      "step": 4775
    },
    {
      "epoch": 1.0750279955207167,
      "grad_norm": 0.3070037066936493,
      "learning_rate": 8.991285528886262e-05,
      "loss": 0.4114,
      "step": 4800
    },
    {
      "epoch": 1.0750279955207167,
      "eval_loss": 0.4781789779663086,
      "eval_runtime": 118.7444,
      "eval_samples_per_second": 31.665,
      "eval_steps_per_second": 3.958,
      "step": 4800
    },
    {
      "epoch": 1.0806270996640537,
      "grad_norm": 0.2807762622833252,
      "learning_rate": 8.902833708087386e-05,
      "loss": 0.4002,
      "step": 4825
    },
    {
      "epoch": 1.0862262038073909,
      "grad_norm": 0.2642569839954376,
      "learning_rate": 8.814468688932111e-05,
      "loss": 0.4056,
      "step": 4850
    },
    {
      "epoch": 1.0918253079507279,
      "grad_norm": 0.2918959856033325,
      "learning_rate": 8.72619746236516e-05,
      "loss": 0.4006,
      "step": 4875
    },
    {
      "epoch": 1.097424412094065,
      "grad_norm": 0.305840402841568,
      "learning_rate": 8.638027011910916e-05,
      "loss": 0.4046,
      "step": 4900
    },
    {
      "epoch": 1.103023516237402,
      "grad_norm": 0.26015645265579224,
      "learning_rate": 8.549964313120915e-05,
      "loss": 0.4257,
      "step": 4925
    },
    {
      "epoch": 1.108622620380739,
      "grad_norm": 0.3089873790740967,
      "learning_rate": 8.462016333021991e-05,
      "loss": 0.4113,
      "step": 4950
    },
    {
      "epoch": 1.1142217245240762,
      "grad_norm": 0.29175418615341187,
      "learning_rate": 8.374190029565072e-05,
      "loss": 0.4003,
      "step": 4975
    },
    {
      "epoch": 1.1198208286674132,
      "grad_norm": 0.2841683328151703,
      "learning_rate": 8.286492351074723e-05,
      "loss": 0.4134,
      "step": 5000
    },
    {
      "epoch": 1.1198208286674132,
      "eval_loss": 0.4782980680465698,
      "eval_runtime": 118.7027,
      "eval_samples_per_second": 31.676,
      "eval_steps_per_second": 3.959,
      "step": 5000
    },
    {
      "epoch": 1.1254199328107504,
      "grad_norm": 0.32862576842308044,
      "learning_rate": 8.198930235699415e-05,
      "loss": 0.4032,
      "step": 5025
    },
    {
      "epoch": 1.1310190369540873,
      "grad_norm": 0.2773643136024475,
      "learning_rate": 8.111510610862628e-05,
      "loss": 0.3959,
      "step": 5050
    },
    {
      "epoch": 1.1366181410974243,
      "grad_norm": 0.27841809391975403,
      "learning_rate": 8.024240392714791e-05,
      "loss": 0.3987,
      "step": 5075
    },
    {
      "epoch": 1.1422172452407615,
      "grad_norm": 0.2690090537071228,
      "learning_rate": 7.937126485586109e-05,
      "loss": 0.3927,
      "step": 5100
    },
    {
      "epoch": 1.1478163493840985,
      "grad_norm": 0.26138368248939514,
      "learning_rate": 7.850175781440338e-05,
      "loss": 0.3986,
      "step": 5125
    },
    {
      "epoch": 1.1534154535274357,
      "grad_norm": 0.2394055873155594,
      "learning_rate": 7.763395159329535e-05,
      "loss": 0.4175,
      "step": 5150
    },
    {
      "epoch": 1.1590145576707727,
      "grad_norm": 0.2714194059371948,
      "learning_rate": 7.676791484849812e-05,
      "loss": 0.4012,
      "step": 5175
    },
    {
      "epoch": 1.1646136618141099,
      "grad_norm": 0.2627696394920349,
      "learning_rate": 7.590371609598184e-05,
      "loss": 0.4071,
      "step": 5200
    },
    {
      "epoch": 1.1646136618141099,
      "eval_loss": 0.4785653054714203,
      "eval_runtime": 118.8145,
      "eval_samples_per_second": 31.646,
      "eval_steps_per_second": 3.956,
      "step": 5200
    },
    {
      "epoch": 1.1702127659574468,
      "grad_norm": 0.2679247260093689,
      "learning_rate": 7.504142370630492e-05,
      "loss": 0.4119,
      "step": 5225
    },
    {
      "epoch": 1.1758118701007838,
      "grad_norm": 0.28891482949256897,
      "learning_rate": 7.418110589920518e-05,
      "loss": 0.3957,
      "step": 5250
    },
    {
      "epoch": 1.181410974244121,
      "grad_norm": 0.30383726954460144,
      "learning_rate": 7.332283073820239e-05,
      "loss": 0.4129,
      "step": 5275
    },
    {
      "epoch": 1.187010078387458,
      "grad_norm": 0.3028230369091034,
      "learning_rate": 7.246666612521371e-05,
      "loss": 0.4141,
      "step": 5300
    },
    {
      "epoch": 1.192609182530795,
      "grad_norm": 0.29802149534225464,
      "learning_rate": 7.161267979518156e-05,
      "loss": 0.4114,
      "step": 5325
    },
    {
      "epoch": 1.1982082866741322,
      "grad_norm": 0.2645573019981384,
      "learning_rate": 7.076093931071483e-05,
      "loss": 0.4047,
      "step": 5350
    },
    {
      "epoch": 1.2038073908174691,
      "grad_norm": 0.2659023702144623,
      "learning_rate": 6.991151205674366e-05,
      "loss": 0.3934,
      "step": 5375
    },
    {
      "epoch": 1.2094064949608063,
      "grad_norm": 0.27495917677879333,
      "learning_rate": 6.906446523518844e-05,
      "loss": 0.4087,
      "step": 5400
    },
    {
      "epoch": 1.2094064949608063,
      "eval_loss": 0.47753679752349854,
      "eval_runtime": 118.6939,
      "eval_samples_per_second": 31.678,
      "eval_steps_per_second": 3.96,
      "step": 5400
    },
    {
      "epoch": 1.2150055991041433,
      "grad_norm": 0.2928061783313751,
      "learning_rate": 6.821986585964304e-05,
      "loss": 0.3972,
      "step": 5425
    },
    {
      "epoch": 1.2206047032474805,
      "grad_norm": 0.30993908643722534,
      "learning_rate": 6.737778075007317e-05,
      "loss": 0.4045,
      "step": 5450
    },
    {
      "epoch": 1.2262038073908175,
      "grad_norm": 0.299959659576416,
      "learning_rate": 6.653827652752986e-05,
      "loss": 0.4057,
      "step": 5475
    },
    {
      "epoch": 1.2318029115341544,
      "grad_norm": 0.2619295120239258,
      "learning_rate": 6.570141960887895e-05,
      "loss": 0.42,
      "step": 5500
    },
    {
      "epoch": 1.2374020156774916,
      "grad_norm": 0.2883395552635193,
      "learning_rate": 6.486727620154624e-05,
      "loss": 0.4097,
      "step": 5525
    },
    {
      "epoch": 1.2430011198208286,
      "grad_norm": 0.2936337888240814,
      "learning_rate": 6.403591229827995e-05,
      "loss": 0.4095,
      "step": 5550
    },
    {
      "epoch": 1.2486002239641658,
      "grad_norm": 0.26269492506980896,
      "learning_rate": 6.320739367192943e-05,
      "loss": 0.4158,
      "step": 5575
    },
    {
      "epoch": 1.2541993281075028,
      "grad_norm": 0.3124653697013855,
      "learning_rate": 6.238178587024166e-05,
      "loss": 0.4146,
      "step": 5600
    },
    {
      "epoch": 1.2541993281075028,
      "eval_loss": 0.4766857922077179,
      "eval_runtime": 118.4407,
      "eval_samples_per_second": 31.746,
      "eval_steps_per_second": 3.968,
      "step": 5600
    },
    {
      "epoch": 1.25979843225084,
      "grad_norm": 0.28966888785362244,
      "learning_rate": 6.155915421067552e-05,
      "loss": 0.3967,
      "step": 5625
    },
    {
      "epoch": 1.265397536394177,
      "grad_norm": 0.2947039008140564,
      "learning_rate": 6.0739563775234195e-05,
      "loss": 0.3855,
      "step": 5650
    },
    {
      "epoch": 1.270996640537514,
      "grad_norm": 0.28155335783958435,
      "learning_rate": 5.992307940531636e-05,
      "loss": 0.4097,
      "step": 5675
    },
    {
      "epoch": 1.2765957446808511,
      "grad_norm": 0.2812201678752899,
      "learning_rate": 5.9109765696586084e-05,
      "loss": 0.4068,
      "step": 5700
    },
    {
      "epoch": 1.282194848824188,
      "grad_norm": 0.26772212982177734,
      "learning_rate": 5.829968699386258e-05,
      "loss": 0.4044,
      "step": 5725
    },
    {
      "epoch": 1.287793952967525,
      "grad_norm": 0.30051615834236145,
      "learning_rate": 5.7492907386029505e-05,
      "loss": 0.4043,
      "step": 5750
    },
    {
      "epoch": 1.2933930571108623,
      "grad_norm": 0.29867812991142273,
      "learning_rate": 5.668949070096463e-05,
      "loss": 0.4019,
      "step": 5775
    },
    {
      "epoch": 1.2989921612541993,
      "grad_norm": 0.2991155982017517,
      "learning_rate": 5.588950050049022e-05,
      "loss": 0.4109,
      "step": 5800
    },
    {
      "epoch": 1.2989921612541993,
      "eval_loss": 0.47626328468322754,
      "eval_runtime": 118.4834,
      "eval_samples_per_second": 31.734,
      "eval_steps_per_second": 3.967,
      "step": 5800
    },
    {
      "epoch": 1.3045912653975364,
      "grad_norm": 0.2992524802684784,
      "learning_rate": 5.509300007534411e-05,
      "loss": 0.4074,
      "step": 5825
    },
    {
      "epoch": 1.3101903695408734,
      "grad_norm": 0.30321359634399414,
      "learning_rate": 5.4300052440172856e-05,
      "loss": 0.4167,
      "step": 5850
    },
    {
      "epoch": 1.3157894736842106,
      "grad_norm": 0.29635748267173767,
      "learning_rate": 5.351072032854613e-05,
      "loss": 0.4094,
      "step": 5875
    },
    {
      "epoch": 1.3213885778275476,
      "grad_norm": 0.29567137360572815,
      "learning_rate": 5.2725066187993685e-05,
      "loss": 0.4078,
      "step": 5900
    },
    {
      "epoch": 1.3269876819708846,
      "grad_norm": 0.2815386950969696,
      "learning_rate": 5.194315217506478e-05,
      "loss": 0.4042,
      "step": 5925
    },
    {
      "epoch": 1.3325867861142218,
      "grad_norm": 0.27265673875808716,
      "learning_rate": 5.116504015041077e-05,
      "loss": 0.4129,
      "step": 5950
    },
    {
      "epoch": 1.3381858902575587,
      "grad_norm": 0.2893974184989929,
      "learning_rate": 5.039079167389106e-05,
      "loss": 0.419,
      "step": 5975
    },
    {
      "epoch": 1.343784994400896,
      "grad_norm": 0.3030889332294464,
      "learning_rate": 4.96204679997028e-05,
      "loss": 0.41,
      "step": 6000
    },
    {
      "epoch": 1.343784994400896,
      "eval_loss": 0.4755627512931824,
      "eval_runtime": 118.5936,
      "eval_samples_per_second": 31.705,
      "eval_steps_per_second": 3.963,
      "step": 6000
    },
    {
      "epoch": 1.349384098544233,
      "grad_norm": 0.2783823609352112,
      "learning_rate": 4.8854130071534696e-05,
      "loss": 0.4134,
      "step": 6025
    },
    {
      "epoch": 1.35498320268757,
      "grad_norm": 0.32155635952949524,
      "learning_rate": 4.809183851774567e-05,
      "loss": 0.401,
      "step": 6050
    },
    {
      "epoch": 1.360582306830907,
      "grad_norm": 0.27497103810310364,
      "learning_rate": 4.733365364656819e-05,
      "loss": 0.4026,
      "step": 6075
    },
    {
      "epoch": 1.366181410974244,
      "grad_norm": 0.29578685760498047,
      "learning_rate": 4.6579635441337e-05,
      "loss": 0.3981,
      "step": 6100
    },
    {
      "epoch": 1.3717805151175813,
      "grad_norm": 0.29991933703422546,
      "learning_rate": 4.5829843555743626e-05,
      "loss": 0.4109,
      "step": 6125
    },
    {
      "epoch": 1.3773796192609182,
      "grad_norm": 0.3044518828392029,
      "learning_rate": 4.5084337309116874e-05,
      "loss": 0.4104,
      "step": 6150
    },
    {
      "epoch": 1.3829787234042552,
      "grad_norm": 0.3071533143520355,
      "learning_rate": 4.434317568172983e-05,
      "loss": 0.3927,
      "step": 6175
    },
    {
      "epoch": 1.3885778275475924,
      "grad_norm": 0.29285067319869995,
      "learning_rate": 4.360641731013371e-05,
      "loss": 0.4135,
      "step": 6200
    },
    {
      "epoch": 1.3885778275475924,
      "eval_loss": 0.4748782515525818,
      "eval_runtime": 118.6046,
      "eval_samples_per_second": 31.702,
      "eval_steps_per_second": 3.963,
      "step": 6200
    },
    {
      "epoch": 1.3941769316909294,
      "grad_norm": 0.29177325963974,
      "learning_rate": 4.2874120482518734e-05,
      "loss": 0.4097,
      "step": 6225
    },
    {
      "epoch": 1.3997760358342666,
      "grad_norm": 0.24249164760112762,
      "learning_rate": 4.2146343134102864e-05,
      "loss": 0.3922,
      "step": 6250
    },
    {
      "epoch": 1.4053751399776035,
      "grad_norm": 0.30473408102989197,
      "learning_rate": 4.14231428425482e-05,
      "loss": 0.4058,
      "step": 6275
    },
    {
      "epoch": 1.4109742441209407,
      "grad_norm": 0.2845681607723236,
      "learning_rate": 4.0704576823405815e-05,
      "loss": 0.4089,
      "step": 6300
    },
    {
      "epoch": 1.4165733482642777,
      "grad_norm": 0.2923874855041504,
      "learning_rate": 3.999070192558901e-05,
      "loss": 0.3999,
      "step": 6325
    },
    {
      "epoch": 1.4221724524076147,
      "grad_norm": 0.32008159160614014,
      "learning_rate": 3.928157462687601e-05,
      "loss": 0.4041,
      "step": 6350
    },
    {
      "epoch": 1.427771556550952,
      "grad_norm": 0.28307563066482544,
      "learning_rate": 3.8577251029441564e-05,
      "loss": 0.4065,
      "step": 6375
    },
    {
      "epoch": 1.4333706606942889,
      "grad_norm": 0.2848350703716278,
      "learning_rate": 3.787778685541856e-05,
      "loss": 0.4075,
      "step": 6400
    },
    {
      "epoch": 1.4333706606942889,
      "eval_loss": 0.47414305806159973,
      "eval_runtime": 118.602,
      "eval_samples_per_second": 31.703,
      "eval_steps_per_second": 3.963,
      "step": 6400
    },
    {
      "epoch": 1.4389697648376258,
      "grad_norm": 0.2576083242893219,
      "learning_rate": 3.718323744248947e-05,
      "loss": 0.4063,
      "step": 6425
    },
    {
      "epoch": 1.444568868980963,
      "grad_norm": 0.27736178040504456,
      "learning_rate": 3.6493657739508527e-05,
      "loss": 0.4063,
      "step": 6450
    },
    {
      "epoch": 1.4501679731243002,
      "grad_norm": 0.3150346577167511,
      "learning_rate": 3.5809102302154326e-05,
      "loss": 0.3974,
      "step": 6475
    },
    {
      "epoch": 1.4557670772676372,
      "grad_norm": 0.2693544328212738,
      "learning_rate": 3.512962528861383e-05,
      "loss": 0.4015,
      "step": 6500
    },
    {
      "epoch": 1.4613661814109742,
      "grad_norm": 0.30606505274772644,
      "learning_rate": 3.4455280455297455e-05,
      "loss": 0.4201,
      "step": 6525
    },
    {
      "epoch": 1.4669652855543114,
      "grad_norm": 0.2886650860309601,
      "learning_rate": 3.37861211525864e-05,
      "loss": 0.4113,
      "step": 6550
    },
    {
      "epoch": 1.4725643896976484,
      "grad_norm": 0.28540754318237305,
      "learning_rate": 3.312220032061175e-05,
      "loss": 0.4087,
      "step": 6575
    },
    {
      "epoch": 1.4781634938409853,
      "grad_norm": 0.27067774534225464,
      "learning_rate": 3.246357048506619e-05,
      "loss": 0.3966,
      "step": 6600
    },
    {
      "epoch": 1.4781634938409853,
      "eval_loss": 0.473531574010849,
      "eval_runtime": 119.6473,
      "eval_samples_per_second": 31.426,
      "eval_steps_per_second": 3.928,
      "step": 6600
    }
  ],
  "logging_steps": 25,
  "max_steps": 8930,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 200,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 6.551399872772536e+17,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
